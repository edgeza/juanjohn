#!/usr/bin/env python3
"""
VectorBTPro Results Ingestion System

This system reads the CSV/JSON results files generated by the VectorBTPro local engine
and ingests them into the PostgreSQL database for the main application to use.

This bridges the gap between local VectorBTPro processing and cloud-based display.
"""

import os
import json
import logging
import psycopg2
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import glob
from psycopg2.extras import RealDictCursor

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s:%(message)s',
    handlers=[
        logging.FileHandler("vectorbt_ingestion.log"),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class VectorBTIngestionSystem:
    def __init__(self, db_config: Dict, results_dir: str = "results"):
        """
        Initialize the VectorBTPro ingestion system
        
        Args:
            db_config: PostgreSQL database configuration
            results_dir: Directory containing analysis results
        """
        self.db_config = db_config
        self.results_dir = results_dir
        self.connection = None
        
    def connect_database(self):
        """Establish database connection"""
        try:
            self.connection = psycopg2.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                database=self.db_config['database'],
                user=self.db_config['user'],
                password=self.db_config['password']
            )
            logger.info("Database connection established")
        except Exception as e:
            logger.error(f"Database connection failed: {e}")
            raise
    
    def close_database(self):
        """Close database connection"""
        if self.connection:
            self.connection.close()
            logger.info("Database connection closed")
    
    def get_latest_results_files(self) -> Dict[str, str]:
        """
        Get the most recent results files (CSV and JSON)
        
        Returns:
            Dictionary with file paths for CSV and JSON
        """
        try:
            files = {}
            
            # Find latest CSV file
            csv_pattern = os.path.join(self.results_dir, "vectorbt_analysis_results_*.csv")
            csv_files = glob.glob(csv_pattern)
            if csv_files:
                csv_files.sort(key=os.path.getmtime, reverse=True)
                files['csv'] = csv_files[0]
                logger.info(f"Found latest CSV file: {files['csv']}")
            
            # Find latest JSON file
            json_pattern = os.path.join(self.results_dir, "vectorbt_analysis_results_*.json")
            json_files = glob.glob(json_pattern)
            if json_files:
                json_files.sort(key=os.path.getmtime, reverse=True)
                files['json'] = json_files[0]
                logger.info(f"Found latest JSON file: {files['json']}")
            
            if not files:
                logger.warning(f"No VectorBTPro results files found in {self.results_dir}")
            
            return files
            
        except Exception as e:
            logger.error(f"Error finding latest results files: {e}")
            return {}
    
    def load_csv_results(self, filepath: str) -> List[Dict]:
        """
        Load analysis results from CSV file
        
        Args:
            filepath: Path to CSV results file
        
        Returns:
            List of dictionaries containing analysis results
        """
        try:
            df = pd.read_csv(filepath)
            results = df.to_dict('records')
            
            logger.info(f"Loaded {len(results)} results from CSV: {filepath}")
            return results
            
        except Exception as e:
            logger.error(f"Error loading CSV results from {filepath}: {e}")
            return []
    
    def load_json_results(self, filepath: str) -> List[Dict]:
        """
        Load analysis results from JSON file
        
        Args:
            filepath: Path to JSON results file
        
        Returns:
            List of dictionaries containing analysis results
        """
        try:
            with open(filepath, 'r') as f:
                results = json.load(f)
            
            logger.info(f"Loaded {len(results)} results from JSON: {filepath}")
            return results
            
        except Exception as e:
            logger.error(f"Error loading JSON results from {filepath}: {e}")
            return []
    
    def create_tables_if_not_exist(self):
        """Create necessary tables if they don't exist"""
        try:
            with self.connection.cursor() as cursor:
                # Create alerts table (if not exists)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS trading.alerts (
                        id SERIAL PRIMARY KEY,
                        symbol VARCHAR(20) NOT NULL,
                        interval VARCHAR(10) NOT NULL,
                        signal VARCHAR(10) NOT NULL,
                        current_price NUMERIC(20,8),
                        upper_band NUMERIC(20,8),
                        lower_band NUMERIC(20,8),
                        potential_return NUMERIC(10,4),
                        total_return NUMERIC(10,4),
                        sharpe_ratio NUMERIC(10,4),
                        max_drawdown NUMERIC(10,4),
                        degree INTEGER,
                        kstd NUMERIC(5,2),
                        analysis_date TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                    )
                """)
                
                # Create vectorbt_analysis table for detailed results
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS trading.vectorbt_analysis (
                        id SERIAL PRIMARY KEY,
                        symbol VARCHAR(20) NOT NULL,
                        interval VARCHAR(10) NOT NULL,
                        analysis_date TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        current_price NUMERIC(20,8),
                        lower_band NUMERIC(20,8),
                        upper_band NUMERIC(20,8),
                        signal VARCHAR(10),
                        potential_return NUMERIC(10,4),
                        total_return NUMERIC(10,4),
                        sharpe_ratio NUMERIC(10,4),
                        max_drawdown NUMERIC(10,4),
                        degree INTEGER,
                        kstd NUMERIC(5,2),
                        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                    )
                """)
                
                # Create indexes for performance
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_alerts_symbol ON trading.alerts(symbol)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_alerts_signal ON trading.alerts(signal)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_alerts_date ON trading.alerts(analysis_date)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_vectorbt_symbol ON trading.vectorbt_analysis(symbol)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_vectorbt_date ON trading.vectorbt_analysis(analysis_date)")
                
                self.connection.commit()
                logger.info("Tables created/verified successfully")
                
        except Exception as e:
            logger.error(f"Error creating tables: {e}")
            self.connection.rollback()
            raise
    
    def ingest_alerts(self, results: List[Dict]) -> int:
        """
        Ingest alert signals into the database
        
        Args:
            results: List of analysis results
        
        Returns:
            Number of alerts ingested
        """
        try:
            ingested_count = 0
            
            with self.connection.cursor() as cursor:
                for result in results:
                    if 'error' in result:
                        logger.warning(f"Skipping {result.get('symbol', 'unknown')}: {result['error']}")
                        continue
                    
                    symbol = result['symbol']
                    signal = result.get('signal', 'HOLD')
                    
                    # Check if alert already exists for this symbol today
                    cursor.execute("""
                        SELECT id FROM trading.alerts 
                        WHERE symbol = %s AND analysis_date::date = CURRENT_DATE
                    """, (symbol,))
                    
                    existing_alert = cursor.fetchone()
                    
                    if existing_alert:
                        # Update existing alert
                        cursor.execute("""
                            UPDATE trading.alerts SET
                                signal = %s,
                                current_price = %s,
                                upper_band = %s,
                                lower_band = %s,
                                potential_return = %s,
                                total_return = %s,
                                sharpe_ratio = %s,
                                max_drawdown = %s,
                                degree = %s,
                                kstd = %s,
                                updated_at = NOW()
                            WHERE id = %s
                        """, (
                            signal,
                            result.get('current_price'),
                            result.get('upper_band'),
                            result.get('lower_band'),
                            result.get('potential_return'),
                            result.get('total_return'),
                            result.get('sharpe_ratio'),
                            result.get('max_drawdown'),
                            result.get('degree'),
                            result.get('kstd'),
                            existing_alert[0]
                        ))
                        logger.info(f"Updated alert for {symbol}")
                    else:
                        # Insert new alert
                        cursor.execute("""
                            INSERT INTO trading.alerts (
                                symbol, interval, signal, current_price, upper_band, lower_band,
                                potential_return, total_return, sharpe_ratio, max_drawdown, degree, kstd
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        """, (
                            symbol,
                            result.get('interval', '1d'),
                            signal,
                            result.get('current_price'),
                            result.get('upper_band'),
                            result.get('lower_band'),
                            result.get('potential_return'),
                            result.get('total_return'),
                            result.get('sharpe_ratio'),
                            result.get('max_drawdown'),
                            result.get('degree'),
                            result.get('kstd')
                        ))
                        logger.info(f"Inserted new alert for {symbol}")
                    
                    ingested_count += 1
            
            self.connection.commit()
            logger.info(f"Successfully ingested {ingested_count} alerts")
            return ingested_count
            
        except Exception as e:
            logger.error(f"Error ingesting alerts: {e}")
            self.connection.rollback()
            return 0
    
    def ingest_vectorbt_analysis(self, results: List[Dict]) -> int:
        """
        Ingest detailed VectorBTPro analysis into the database
        
        Args:
            results: List of analysis results
        
        Returns:
            Number of analysis records ingested
        """
        try:
            ingested_count = 0
            
            with self.connection.cursor() as cursor:
                for result in results:
                    if 'error' in result:
                        continue
                    
                    symbol = result['symbol']
                    
                    # Check if analysis already exists for this symbol today
                    cursor.execute("""
                        SELECT id FROM trading.vectorbt_analysis 
                        WHERE symbol = %s AND analysis_date::date = CURRENT_DATE
                    """, (symbol,))
                    
                    existing_analysis = cursor.fetchone()
                    
                    if existing_analysis:
                        # Update existing analysis
                        cursor.execute("""
                            UPDATE trading.vectorbt_analysis SET
                                current_price = %s,
                                lower_band = %s,
                                upper_band = %s,
                                signal = %s,
                                potential_return = %s,
                                total_return = %s,
                                sharpe_ratio = %s,
                                max_drawdown = %s,
                                degree = %s,
                                kstd = %s
                            WHERE id = %s
                        """, (
                            result.get('current_price'),
                            result.get('lower_band'),
                            result.get('upper_band'),
                            result.get('signal'),
                            result.get('potential_return'),
                            result.get('total_return'),
                            result.get('sharpe_ratio'),
                            result.get('max_drawdown'),
                            result.get('degree'),
                            result.get('kstd'),
                            existing_analysis[0]
                        ))
                        logger.info(f"Updated analysis for {symbol}")
                    else:
                        # Insert new analysis
                        cursor.execute("""
                            INSERT INTO trading.vectorbt_analysis (
                                symbol, interval, current_price, lower_band, upper_band,
                                signal, potential_return, total_return, sharpe_ratio, max_drawdown,
                                degree, kstd
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        """, (
                            symbol,
                            result.get('interval', '1d'),
                            result.get('current_price'),
                            result.get('lower_band'),
                            result.get('upper_band'),
                            result.get('signal'),
                            result.get('potential_return'),
                            result.get('total_return'),
                            result.get('sharpe_ratio'),
                            result.get('max_drawdown'),
                            result.get('degree'),
                            result.get('kstd')
                        ))
                        logger.info(f"Inserted new analysis for {symbol}")
                    
                    ingested_count += 1
            
            self.connection.commit()
            logger.info(f"Successfully ingested {ingested_count} VectorBTPro analysis records")
            return ingested_count
            
        except Exception as e:
            logger.error(f"Error ingesting VectorBTPro analysis: {e}")
            self.connection.rollback()
            return 0
    
    def cleanup_old_data(self, days: int = 30):
        """
        Clean up old data to prevent database bloat
        
        Args:
            days: Number of days to keep data
        """
        try:
            with self.connection.cursor() as cursor:
                # Clean up old alerts
                cursor.execute("""
                    DELETE FROM trading.alerts 
                    WHERE created_at < NOW() - INTERVAL '%s days'
                """, (days,))
                alerts_deleted = cursor.rowcount
                
                # Clean up old VectorBTPro analysis
                cursor.execute("""
                    DELETE FROM trading.vectorbt_analysis 
                    WHERE created_at < NOW() - INTERVAL '%s days'
                """, (days,))
                analysis_deleted = cursor.rowcount
                
                self.connection.commit()
                logger.info(f"Cleanup completed: {alerts_deleted} alerts, {analysis_deleted} analysis records deleted")
                
        except Exception as e:
            logger.error(f"Error during cleanup: {e}")
            self.connection.rollback()
    
    def ingest_latest_results(self) -> Dict:
        """
        Ingest the latest VectorBTPro analysis results
        
        Returns:
            Dictionary with ingestion results
        """
        try:
            # Connect to database
            self.connect_database()
            
            # Create tables if they don't exist
            self.create_tables_if_not_exist()
            
            # Get latest results files
            files = self.get_latest_results_files()
            if not files:
                return {'error': 'No VectorBTPro results files found'}
            
            results = []
            
            # Load results from available files
            if 'csv' in files:
                csv_results = self.load_csv_results(files['csv'])
                results.extend(csv_results)
                logger.info(f"Loaded {len(csv_results)} results from CSV")
            
            if 'json' in files:
                json_results = self.load_json_results(files['json'])
                results.extend(json_results)
                logger.info(f"Loaded {len(json_results)} results from JSON")
            
            if not results:
                return {'error': 'Failed to load results from files'}
            
            # Remove duplicates (in case both CSV and JSON contain same data)
            seen = set()
            unique_results = []
            for result in results:
                key = f"{result.get('symbol')}_{result.get('interval', '1d')}"
                if key not in seen:
                    seen.add(key)
                    unique_results.append(result)
            
            logger.info(f"Processing {len(unique_results)} unique results")
            
            # Ingest data
            alerts_ingested = self.ingest_alerts(unique_results)
            analysis_ingested = self.ingest_vectorbt_analysis(unique_results)
            
            # Cleanup old data
            self.cleanup_old_data()
            
            # Close database connection
            self.close_database()
            
            return {
                'success': True,
                'files_processed': list(files.values()),
                'total_results': len(results),
                'unique_results': len(unique_results),
                'alerts_ingested': alerts_ingested,
                'analysis_ingested': analysis_ingested,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error during ingestion: {e}")
            if self.connection:
                self.close_database()
            return {'error': str(e)}

def main():
    """Main function for running the VectorBTPro ingestion system"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Ingest VectorBTPro analysis results into database')
    parser.add_argument('--config', default='config.json', help='Configuration file path')
    parser.add_argument('--results-dir', default='results', help='Results directory path')
    parser.add_argument('--cleanup-days', type=int, default=30, help='Days to keep data')
    
    args = parser.parse_args()
    
    # Load configuration
    try:
        with open(args.config, 'r') as f:
            config = json.load(f)
    except Exception as e:
        print(f"Error loading config: {e}")
        return
    
    # Database configuration
    db_config = {
        'host': config.get('database_host', 'localhost'),
        'port': config.get('database_port', 5432),
        'database': config.get('database_name', 'autonama'),
        'user': config.get('database_user', 'postgres'),
        'password': config.get('database_password', 'postgres')
    }
    
    # Initialize and run ingestion
    ingestion_system = VectorBTIngestionSystem(db_config, args.results_dir)
    results = ingestion_system.ingest_latest_results()
    
    if 'error' in results:
        print(f"‚ùå Ingestion failed: {results['error']}")
    else:
        print(f"‚úÖ VectorBTPro ingestion completed successfully!")
        print(f"üìÅ Files processed: {', '.join(results['files_processed'])}")
        print(f"üìä Total results: {results['total_results']}")
        print(f"üîç Unique results: {results['unique_results']}")
        print(f"üìä Alerts ingested: {results['alerts_ingested']}")
        print(f"üìà Analysis ingested: {results['analysis_ingested']}")

if __name__ == "__main__":
    main() 
"""
VectorBTPro Results Ingestion System

This system reads the CSV/JSON results files generated by the VectorBTPro local engine
and ingests them into the PostgreSQL database for the main application to use.

This bridges the gap between local VectorBTPro processing and cloud-based display.
"""

import os
import json
import logging
import psycopg2
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import glob
from psycopg2.extras import RealDictCursor

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s:%(message)s',
    handlers=[
        logging.FileHandler("vectorbt_ingestion.log"),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class VectorBTIngestionSystem:
    def __init__(self, db_config: Dict, results_dir: str = "results"):
        """
        Initialize the VectorBTPro ingestion system
        
        Args:
            db_config: PostgreSQL database configuration
            results_dir: Directory containing analysis results
        """
        self.db_config = db_config
        self.results_dir = results_dir
        self.connection = None
        
    def connect_database(self):
        """Establish database connection"""
        try:
            self.connection = psycopg2.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                database=self.db_config['database'],
                user=self.db_config['user'],
                password=self.db_config['password']
            )
            logger.info("Database connection established")
        except Exception as e:
            logger.error(f"Database connection failed: {e}")
            raise
    
    def close_database(self):
        """Close database connection"""
        if self.connection:
            self.connection.close()
            logger.info("Database connection closed")
    
    def get_latest_results_files(self) -> Dict[str, str]:
        """
        Get the most recent results files (CSV and JSON)
        
        Returns:
            Dictionary with file paths for CSV and JSON
        """
        try:
            files = {}
            
            # Find latest CSV file
            csv_pattern = os.path.join(self.results_dir, "vectorbt_analysis_results_*.csv")
            csv_files = glob.glob(csv_pattern)
            if csv_files:
                csv_files.sort(key=os.path.getmtime, reverse=True)
                files['csv'] = csv_files[0]
                logger.info(f"Found latest CSV file: {files['csv']}")
            
            # Find latest JSON file
            json_pattern = os.path.join(self.results_dir, "vectorbt_analysis_results_*.json")
            json_files = glob.glob(json_pattern)
            if json_files:
                json_files.sort(key=os.path.getmtime, reverse=True)
                files['json'] = json_files[0]
                logger.info(f"Found latest JSON file: {files['json']}")
            
            if not files:
                logger.warning(f"No VectorBTPro results files found in {self.results_dir}")
            
            return files
            
        except Exception as e:
            logger.error(f"Error finding latest results files: {e}")
            return {}
    
    def load_csv_results(self, filepath: str) -> List[Dict]:
        """
        Load analysis results from CSV file
        
        Args:
            filepath: Path to CSV results file
        
        Returns:
            List of dictionaries containing analysis results
        """
        try:
            df = pd.read_csv(filepath)
            results = df.to_dict('records')
            
            logger.info(f"Loaded {len(results)} results from CSV: {filepath}")
            return results
            
        except Exception as e:
            logger.error(f"Error loading CSV results from {filepath}: {e}")
            return []
    
    def load_json_results(self, filepath: str) -> List[Dict]:
        """
        Load analysis results from JSON file
        
        Args:
            filepath: Path to JSON results file
        
        Returns:
            List of dictionaries containing analysis results
        """
        try:
            with open(filepath, 'r') as f:
                results = json.load(f)
            
            logger.info(f"Loaded {len(results)} results from JSON: {filepath}")
            return results
            
        except Exception as e:
            logger.error(f"Error loading JSON results from {filepath}: {e}")
            return []
    
    def create_tables_if_not_exist(self):
        """Create necessary tables if they don't exist"""
        try:
            with self.connection.cursor() as cursor:
                # Create alerts table (if not exists)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS trading.alerts (
                        id SERIAL PRIMARY KEY,
                        symbol VARCHAR(20) NOT NULL,
                        interval VARCHAR(10) NOT NULL,
                        signal VARCHAR(10) NOT NULL,
                        current_price NUMERIC(20,8),
                        upper_band NUMERIC(20,8),
                        lower_band NUMERIC(20,8),
                        potential_return NUMERIC(10,4),
                        total_return NUMERIC(10,4),
                        sharpe_ratio NUMERIC(10,4),
                        max_drawdown NUMERIC(10,4),
                        degree INTEGER,
                        kstd NUMERIC(5,2),
                        analysis_date TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                    )
                """)
                
                # Create vectorbt_analysis table for detailed results
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS trading.vectorbt_analysis (
                        id SERIAL PRIMARY KEY,
                        symbol VARCHAR(20) NOT NULL,
                        interval VARCHAR(10) NOT NULL,
                        analysis_date TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        current_price NUMERIC(20,8),
                        lower_band NUMERIC(20,8),
                        upper_band NUMERIC(20,8),
                        signal VARCHAR(10),
                        potential_return NUMERIC(10,4),
                        total_return NUMERIC(10,4),
                        sharpe_ratio NUMERIC(10,4),
                        max_drawdown NUMERIC(10,4),
                        degree INTEGER,
                        kstd NUMERIC(5,2),
                        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                    )
                """)
                
                # Create indexes for performance
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_alerts_symbol ON trading.alerts(symbol)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_alerts_signal ON trading.alerts(signal)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_alerts_date ON trading.alerts(analysis_date)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_vectorbt_symbol ON trading.vectorbt_analysis(symbol)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_vectorbt_date ON trading.vectorbt_analysis(analysis_date)")
                
                self.connection.commit()
                logger.info("Tables created/verified successfully")
                
        except Exception as e:
            logger.error(f"Error creating tables: {e}")
            self.connection.rollback()
            raise
    
    def ingest_alerts(self, results: List[Dict]) -> int:
        """
        Ingest alert signals into the database
        
        Args:
            results: List of analysis results
        
        Returns:
            Number of alerts ingested
        """
        try:
            ingested_count = 0
            
            with self.connection.cursor() as cursor:
                for result in results:
                    if 'error' in result:
                        logger.warning(f"Skipping {result.get('symbol', 'unknown')}: {result['error']}")
                        continue
                    
                    symbol = result['symbol']
                    signal = result.get('signal', 'HOLD')
                    
                    # Check if alert already exists for this symbol today
                    cursor.execute("""
                        SELECT id FROM trading.alerts 
                        WHERE symbol = %s AND analysis_date::date = CURRENT_DATE
                    """, (symbol,))
                    
                    existing_alert = cursor.fetchone()
                    
                    if existing_alert:
                        # Update existing alert
                        cursor.execute("""
                            UPDATE trading.alerts SET
                                signal = %s,
                                current_price = %s,
                                upper_band = %s,
                                lower_band = %s,
                                potential_return = %s,
                                total_return = %s,
                                sharpe_ratio = %s,
                                max_drawdown = %s,
                                degree = %s,
                                kstd = %s,
                                updated_at = NOW()
                            WHERE id = %s
                        """, (
                            signal,
                            result.get('current_price'),
                            result.get('upper_band'),
                            result.get('lower_band'),
                            result.get('potential_return'),
                            result.get('total_return'),
                            result.get('sharpe_ratio'),
                            result.get('max_drawdown'),
                            result.get('degree'),
                            result.get('kstd'),
                            existing_alert[0]
                        ))
                        logger.info(f"Updated alert for {symbol}")
                    else:
                        # Insert new alert
                        cursor.execute("""
                            INSERT INTO trading.alerts (
                                symbol, interval, signal, current_price, upper_band, lower_band,
                                potential_return, total_return, sharpe_ratio, max_drawdown, degree, kstd
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        """, (
                            symbol,
                            result.get('interval', '1d'),
                            signal,
                            result.get('current_price'),
                            result.get('upper_band'),
                            result.get('lower_band'),
                            result.get('potential_return'),
                            result.get('total_return'),
                            result.get('sharpe_ratio'),
                            result.get('max_drawdown'),
                            result.get('degree'),
                            result.get('kstd')
                        ))
                        logger.info(f"Inserted new alert for {symbol}")
                    
                    ingested_count += 1
            
            self.connection.commit()
            logger.info(f"Successfully ingested {ingested_count} alerts")
            return ingested_count
            
        except Exception as e:
            logger.error(f"Error ingesting alerts: {e}")
            self.connection.rollback()
            return 0
    
    def ingest_vectorbt_analysis(self, results: List[Dict]) -> int:
        """
        Ingest detailed VectorBTPro analysis into the database
        
        Args:
            results: List of analysis results
        
        Returns:
            Number of analysis records ingested
        """
        try:
            ingested_count = 0
            
            with self.connection.cursor() as cursor:
                for result in results:
                    if 'error' in result:
                        continue
                    
                    symbol = result['symbol']
                    
                    # Check if analysis already exists for this symbol today
                    cursor.execute("""
                        SELECT id FROM trading.vectorbt_analysis 
                        WHERE symbol = %s AND analysis_date::date = CURRENT_DATE
                    """, (symbol,))
                    
                    existing_analysis = cursor.fetchone()
                    
                    if existing_analysis:
                        # Update existing analysis
                        cursor.execute("""
                            UPDATE trading.vectorbt_analysis SET
                                current_price = %s,
                                lower_band = %s,
                                upper_band = %s,
                                signal = %s,
                                potential_return = %s,
                                total_return = %s,
                                sharpe_ratio = %s,
                                max_drawdown = %s,
                                degree = %s,
                                kstd = %s
                            WHERE id = %s
                        """, (
                            result.get('current_price'),
                            result.get('lower_band'),
                            result.get('upper_band'),
                            result.get('signal'),
                            result.get('potential_return'),
                            result.get('total_return'),
                            result.get('sharpe_ratio'),
                            result.get('max_drawdown'),
                            result.get('degree'),
                            result.get('kstd'),
                            existing_analysis[0]
                        ))
                        logger.info(f"Updated analysis for {symbol}")
                    else:
                        # Insert new analysis
                        cursor.execute("""
                            INSERT INTO trading.vectorbt_analysis (
                                symbol, interval, current_price, lower_band, upper_band,
                                signal, potential_return, total_return, sharpe_ratio, max_drawdown,
                                degree, kstd
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        """, (
                            symbol,
                            result.get('interval', '1d'),
                            result.get('current_price'),
                            result.get('lower_band'),
                            result.get('upper_band'),
                            result.get('signal'),
                            result.get('potential_return'),
                            result.get('total_return'),
                            result.get('sharpe_ratio'),
                            result.get('max_drawdown'),
                            result.get('degree'),
                            result.get('kstd')
                        ))
                        logger.info(f"Inserted new analysis for {symbol}")
                    
                    ingested_count += 1
            
            self.connection.commit()
            logger.info(f"Successfully ingested {ingested_count} VectorBTPro analysis records")
            return ingested_count
            
        except Exception as e:
            logger.error(f"Error ingesting VectorBTPro analysis: {e}")
            self.connection.rollback()
            return 0
    
    def cleanup_old_data(self, days: int = 30):
        """
        Clean up old data to prevent database bloat
        
        Args:
            days: Number of days to keep data
        """
        try:
            with self.connection.cursor() as cursor:
                # Clean up old alerts
                cursor.execute("""
                    DELETE FROM trading.alerts 
                    WHERE created_at < NOW() - INTERVAL '%s days'
                """, (days,))
                alerts_deleted = cursor.rowcount
                
                # Clean up old VectorBTPro analysis
                cursor.execute("""
                    DELETE FROM trading.vectorbt_analysis 
                    WHERE created_at < NOW() - INTERVAL '%s days'
                """, (days,))
                analysis_deleted = cursor.rowcount
                
                self.connection.commit()
                logger.info(f"Cleanup completed: {alerts_deleted} alerts, {analysis_deleted} analysis records deleted")
                
        except Exception as e:
            logger.error(f"Error during cleanup: {e}")
            self.connection.rollback()
    
    def ingest_latest_results(self) -> Dict:
        """
        Ingest the latest VectorBTPro analysis results
        
        Returns:
            Dictionary with ingestion results
        """
        try:
            # Connect to database
            self.connect_database()
            
            # Create tables if they don't exist
            self.create_tables_if_not_exist()
            
            # Get latest results files
            files = self.get_latest_results_files()
            if not files:
                return {'error': 'No VectorBTPro results files found'}
            
            results = []
            
            # Load results from available files
            if 'csv' in files:
                csv_results = self.load_csv_results(files['csv'])
                results.extend(csv_results)
                logger.info(f"Loaded {len(csv_results)} results from CSV")
            
            if 'json' in files:
                json_results = self.load_json_results(files['json'])
                results.extend(json_results)
                logger.info(f"Loaded {len(json_results)} results from JSON")
            
            if not results:
                return {'error': 'Failed to load results from files'}
            
            # Remove duplicates (in case both CSV and JSON contain same data)
            seen = set()
            unique_results = []
            for result in results:
                key = f"{result.get('symbol')}_{result.get('interval', '1d')}"
                if key not in seen:
                    seen.add(key)
                    unique_results.append(result)
            
            logger.info(f"Processing {len(unique_results)} unique results")
            
            # Ingest data
            alerts_ingested = self.ingest_alerts(unique_results)
            analysis_ingested = self.ingest_vectorbt_analysis(unique_results)
            
            # Cleanup old data
            self.cleanup_old_data()
            
            # Close database connection
            self.close_database()
            
            return {
                'success': True,
                'files_processed': list(files.values()),
                'total_results': len(results),
                'unique_results': len(unique_results),
                'alerts_ingested': alerts_ingested,
                'analysis_ingested': analysis_ingested,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error during ingestion: {e}")
            if self.connection:
                self.close_database()
            return {'error': str(e)}

def main():
    """Main function for running the VectorBTPro ingestion system"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Ingest VectorBTPro analysis results into database')
    parser.add_argument('--config', default='config.json', help='Configuration file path')
    parser.add_argument('--results-dir', default='results', help='Results directory path')
    parser.add_argument('--cleanup-days', type=int, default=30, help='Days to keep data')
    
    args = parser.parse_args()
    
    # Load configuration
    try:
        with open(args.config, 'r') as f:
            config = json.load(f)
    except Exception as e:
        print(f"Error loading config: {e}")
        return
    
    # Database configuration
    db_config = {
        'host': config.get('database_host', 'localhost'),
        'port': config.get('database_port', 5432),
        'database': config.get('database_name', 'autonama'),
        'user': config.get('database_user', 'postgres'),
        'password': config.get('database_password', 'postgres')
    }
    
    # Initialize and run ingestion
    ingestion_system = VectorBTIngestionSystem(db_config, args.results_dir)
    results = ingestion_system.ingest_latest_results()
    
    if 'error' in results:
        print(f"‚ùå Ingestion failed: {results['error']}")
    else:
        print(f"‚úÖ VectorBTPro ingestion completed successfully!")
        print(f"üìÅ Files processed: {', '.join(results['files_processed'])}")
        print(f"üìä Total results: {results['total_results']}")
        print(f"üîç Unique results: {results['unique_results']}")
        print(f"üìä Alerts ingested: {results['alerts_ingested']}")
        print(f"üìà Analysis ingested: {results['analysis_ingested']}")

if __name__ == "__main__":
    main() 
 